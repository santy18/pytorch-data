{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073bc0f0-e54e-4859-a9ae-a0d67a811a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.7468\n",
      "Epoch 10 Loss: 0.6904\n",
      "Epoch 20 Loss: 0.6648\n",
      "Epoch 30 Loss: 0.6411\n",
      "Epoch 40 Loss: 0.6190\n",
      "Epoch 50 Loss: 0.5984\n",
      "Epoch 60 Loss: 0.5791\n",
      "Epoch 70 Loss: 0.5611\n",
      "Epoch 80 Loss: 0.5442\n",
      "Epoch 90 Loss: 0.5283\n",
      "Predictions: tensor([[0.4408],\n",
      "        [0.5794]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Create dummy data\n",
    "X = torch.tensor([[1.0, 2.0], [2.0, 1.0], [2.5, 2.5], [3.0, 1.0], [1.0, 3.0], [4.0, 5.0]], dtype=torch.float32)\n",
    "y = torch.tensor([0, 0, 0, 1, 0, 1], dtype=torch.float32).unsqueeze(1)  # shape (N, 1)\n",
    "\n",
    "# 2. Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 1),  # input: 2 features, output: 1\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# 3. Define loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss — good for binary classification.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1) # Stochastic Gradient Descent with learning rate 0.1.\n",
    "\n",
    "# 4. Train the model\n",
    "for epoch in range(100):\n",
    "    y_pred = model(X) #Forward pass – get predictions.\n",
    "    loss = criterion(y_pred, y) #Calculate loss between prediction and actual.\n",
    "\n",
    "    optimizer.zero_grad() # Clear gradients from last step.\n",
    "    loss.backward() # Backpropagate to compute gradients.\n",
    "    optimizer.step() #Update model weights using gradients.\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} Loss: {loss.detach().item():.4f}\") # Extract scalar loss (detached from computation graph) and save for plotting.\n",
    "\n",
    "# 5. Test the model\n",
    "with torch.no_grad():\n",
    "    test = torch.tensor([[2.0, 2.0], [4.0, 4.0]], dtype=torch.float32)\n",
    "    preds = model(test)\n",
    "    print(\"Predictions:\", preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95734c10-27ac-49a1-970e-622d5a72a7cb",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "```\n",
    "serWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
    "Consider using tensor.detach() first. (Triggered internally at /opt/pytorch/aten/src/ATen/native/Scalar.cpp:22.)\n",
    "  print(f\"Epoch {epoch} Loss: {loss.item():.4f}\")\n",
    "```\n",
    "Explicitly detach the tensor before calling .item():\n",
    "\n",
    "\n",
    "This happens when you call `.item()` directly on a tensor that tracks gradients (like `loss` in training). While harmless in logging, it's best to explicitly detach it.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Fix\n",
    "\n",
    "Replace this line:\n",
    "\n",
    "```python\n",
    "print(f\"Epoch {epoch} Loss: {loss.item():.4f}\")\n",
    "````\n",
    "\n",
    "with:\n",
    "```\n",
    "print(f\"Epoch {epoch} Loss: {loss.detach().item():.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb089922-4834-4c9f-9c04-e4de842001d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"/simple_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77932e08-dae1-4c4d-9e4f-3aea457ab240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model for inference\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 1), # Takes 2 inputs (x, y) and outputs 1 value.\n",
    "    nn.Sigmoid() # Squashes output to [0,1], representing probability of class 1.\n",
    ")\n",
    "model.load_state_dict(torch.load(\"simple_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58f4800c-0f39-46fa-8d39-ba2e6216e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tensor([[0.4408],\n",
      "        [0.5794]])\n",
      "Class labels: tensor([[0],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Predict new points\n",
    "with torch.no_grad():\n",
    "    test_points = torch.tensor([[2.0, 2.0], [4.0, 4.0]], dtype=torch.float32)\n",
    "    preds = model(test_points)\n",
    "    print(\"Predictions:\", preds)\n",
    "    print(\"Class labels:\", (preds > 0.5).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3257ebc-ff1d-49ee-ac17-9cb0ae7d4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
